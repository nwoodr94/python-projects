{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d41672bd8510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "# This is a binary KNN classifier originally designed to classify \"Good\" (1) or \"Bad\" (0)\n",
    "# movies from imdb data\n",
    "# For example, movies with high box office earnings, and high ratings were labeled (1),\n",
    "# and vice versa for (0)\n",
    "\n",
    "\n",
    "# Euclidean distance calculation\n",
    "def euclidean_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += (pt1[i] - pt2[i]) ** 2\n",
    "    return distance ** 0.5\n",
    "\n",
    "# KNN Classifiers require normalized data so that one feature doesn't dominate the\n",
    "# others simply by virtue of relative integer sizes\n",
    "def min_max_normalize(lst):\n",
    "    minimum = min(lst)\n",
    "    maximum = max(lst)\n",
    "    normalized = []\n",
    "    for i in lst:\n",
    "        normalized_i = (i - minimum)/(maximum - minimum)\n",
    "        normalized.append(normalized_i)\n",
    "    return normalized\n",
    "\n",
    "# This function will take an unlabeled point, and perform the binary classification dependent\n",
    "# upon the known classification of its neighbors\n",
    "def classify(unlabeled_point, dataset, labels, k):\n",
    "    distances = []\n",
    "# Compute the euclidean distance between the unknown point, and the rest of the dataset  \n",
    "    for datapoint in dataset:    \n",
    "        distance_to_point = euclidean_distance(dataset[datapoint], unlabeled_point)\n",
    "# Append the calculated distances to the distance vector and sort them so the head\n",
    "# contains all the closest distances\n",
    "        distances.append([distance_to_point, datapoint])\n",
    "    distances.sort()\n",
    "# We have to select a large enough k to give the alogorithm a good understanding of \n",
    "# its neighboring data, but small enough that it doesn't associate with other data\n",
    "    neighbors = distances[0:k]\n",
    "    num_1 = 0\n",
    "    num_0 = 0\n",
    "# For each neighbor, we read the label to check if it's a 1 or a 0, and return the majority,\n",
    "# ultimately enabling our classification of the unlabeled_point\n",
    "    for neighbor in neighbors:\n",
    "        datapoint = neighbor[1]\n",
    "        if labels[datapoint] == 1:\n",
    "            num_1 += 1\n",
    "        elif labels[datapoint] == 0:\n",
    "            num_0 += 1\n",
    "    if num_1 > num_0:\n",
    "        return \"1\"\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "# We can test the accuracy of our model by splitting the imdb data into training and test\n",
    "# sets and labels\n",
    "\n",
    "# find_test_accuracy checks each test set classification and compares it to the known test\n",
    "# labels\n",
    "def find_test_accuracy(training_set, training_labels, test_set, test_labels, k):\n",
    "    num_correct = 0.0\n",
    "    for i in test_set:\n",
    "        guess = classify(test_set[i], training_set, training_labels, k)\n",
    "        if guess == test_labels[i]:\n",
    "            num_correct += 1\n",
    "    return num_correct / len(test_set)\n",
    "\n",
    "# get_k_vector obtains the test accuracy for a range of k values, allowing us to select the \n",
    "# k which produces the most accurate results.\n",
    "def get_k_vector(k):\n",
    "    k_vals = []\n",
    "    for i in range(k):\n",
    "        k_vals = np.append(k_vals, find_test_accuracy(training_set, training_labels, test_set, test_labels, i))\n",
    "    return k_vals\n",
    "\n",
    "# plot the k vector to visualize classification results and select optimum k\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "#plt.scatter(range(k), k_vals)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
